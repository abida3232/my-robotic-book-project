"use strict";(globalThis.webpackChunkmy_robotic_book=globalThis.webpackChunkmy_robotic_book||[]).push([[5508],{8188:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>l,contentTitle:()=>r,default:()=>h,frontMatter:()=>t,metadata:()=>o,toc:()=>c});const o=JSON.parse('{"id":"part1-foundations/chapter2-landscape","title":"Chapter 2 - The Landscape of Physical AI","description":"2.1 Current Trends and Research Areas","source":"@site/docs/part1-foundations/chapter2-landscape.md","sourceDirName":"part1-foundations","slug":"/part1-foundations/chapter2-landscape","permalink":"/my-robotic-book-project/docs/part1-foundations/chapter2-landscape","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/part1-foundations/chapter2-landscape.md","tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"sidebar_position":2,"title":"Chapter 2 - The Landscape of Physical AI"},"sidebar":"bookSidebar","previous":{"title":"Chapter 1 - Principles of Physical AI","permalink":"/my-robotic-book-project/docs/part1-foundations/chapter1-principles"},"next":{"title":"Chapter 3 - Sensors for Physical AI","permalink":"/my-robotic-book-project/docs/part1-foundations/chapter3-sensors"}}');var a=i(4848),s=i(8453);const t={sidebar_position:2,title:"Chapter 2 - The Landscape of Physical AI"},r="Chapter 2: The Landscape of Physical AI",l={},c=[{value:"2.1 Current Trends and Research Areas",id:"21-current-trends-and-research-areas",level:2},{value:"2.1.1 Overview of Significant Advancements",id:"211-overview-of-significant-advancements",level:3},{value:"2.1.2 Embodied Learning",id:"212-embodied-learning",level:3},{value:"2.1.3 Human-Robot Interaction (HRI)",id:"213-human-robot-interaction-hri",level:3},{value:"2.2 Key Technologies and Platforms",id:"22-key-technologies-and-platforms",level:2},{value:"2.2.1 Robotics Frameworks",id:"221-robotics-frameworks",level:3},{value:"2.2.2 Hardware Platforms for Physical AI",id:"222-hardware-platforms-for-physical-ai",level:3},{value:"2.2.3 Computational Infrastructure",id:"223-computational-infrastructure",level:3},{value:"2.3 Ethical Considerations in Physical AI",id:"23-ethical-considerations-in-physical-ai",level:2},{value:"2.3.1 Safety and Responsibility",id:"231-safety-and-responsibility",level:3},{value:"2.3.2 Privacy and Data Security",id:"232-privacy-and-data-security",level:3},{value:"2.3.3 Societal Impact",id:"233-societal-impact",level:3},{value:"2.4 Future Outlook",id:"24-future-outlook",level:2},{value:"2.4.1 Near-Term Breakthroughs",id:"241-near-term-breakthroughs",level:3},{value:"2.4.2 Long-Term Vision",id:"242-long-term-vision",level:3},{value:"2.4.3 Challenges Ahead",id:"243-challenges-ahead",level:3}];function d(e){const n={h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",p:"p",strong:"strong",ul:"ul",...(0,s.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(n.header,{children:(0,a.jsx)(n.h1,{id:"chapter-2-the-landscape-of-physical-ai",children:"Chapter 2: The Landscape of Physical AI"})}),"\n",(0,a.jsx)(n.h2,{id:"21-current-trends-and-research-areas",children:"2.1 Current Trends and Research Areas"}),"\n",(0,a.jsx)(n.p,{children:"The landscape of Physical AI is constantly evolving, driven by breakthroughs in core AI methodologies and the increasing capabilities of robotic hardware. Several key trends and active research areas are shaping the direction of this field."}),"\n",(0,a.jsx)(n.h3,{id:"211-overview-of-significant-advancements",children:"2.1.1 Overview of Significant Advancements"}),"\n",(0,a.jsx)(n.p,{children:"Recent years have seen remarkable progress, often at the intersection of AI and robotics:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Reinforcement Learning for Robotic Control:"})," Deep Reinforcement Learning (DRL) has enabled robots to learn complex motor skills and control policies directly from experience, often in simulation. This has led to impressive results in tasks like locomotion, manipulation, and even human-robot interaction."]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Simulation-to-Reality (Sim2Real) Transfer:"})," Bridging the gap between behaviors learned in simulation and their successful execution on physical robots is a critical research area. Techniques like domain randomization, domain adaptation, and system identification are being developed to make Sim2Real transfer more robust and reliable, significantly accelerating development cycles."]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Large Language Models (LLMs) in Robotics:"})," The advent of powerful LLMs is opening new avenues for natural language interaction with robots, high-level task planning, and even code generation for robotic behaviors. LLMs can help robots understand complex human commands, reason about tasks, and even adapt to new instructions without extensive re-programming."]}),"\n"]}),"\n",(0,a.jsx)(n.h3,{id:"212-embodied-learning",children:"2.1.2 Embodied Learning"}),"\n",(0,a.jsx)(n.p,{children:"Embodied learning focuses on how robots acquire skills and knowledge through direct physical interaction with their environment. This area explores:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Learning from Physical Interaction:"})," Robots learn by doing, much like humans. This includes techniques such as imitation learning (learning from demonstrations), self-supervised exploration (where the robot generates its own learning signals), and reinforcement learning in real-world settings."]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Data Efficiency in Embodied Learning:"})," Acquiring large datasets in the real world is expensive and time-consuming. Research in this area aims to develop methods that allow robots to learn effectively from limited real-world data, often by combining real and simulated experiences."]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Role of Curiosity and Intrinsic Motivation:"})," To facilitate autonomous exploration and learning, researchers are endowing robots with intrinsic motivation mechanisms, such as curiosity (desire to explore novel situations) or competence-based learning, allowing them to learn without explicit external rewards."]}),"\n"]}),"\n",(0,a.jsx)(n.h3,{id:"213-human-robot-interaction-hri",children:"2.1.3 Human-Robot Interaction (HRI)"}),"\n",(0,a.jsx)(n.p,{children:"As robots become more ubiquitous, effective and safe human-robot interaction (HRI) is paramount. This area addresses:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Challenges in HRI:"})," These include ensuring human safety in shared workspaces, building trust between humans and robots, developing intuitive communication interfaces (verbal and non-verbal), and understanding human intent and preferences."]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Opportunities:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Collaborative Robotics (Cobots):"})," Robots designed to work alongside humans, augmenting human capabilities in manufacturing, healthcare, and logistics."]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Assistive Robotics:"})," Robots providing physical or cognitive assistance to individuals in homes, hospitals, or rehabilitation centers."]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Social Robots:"})," Robots designed for companionship, education, or entertainment, requiring advanced social intelligence and communication skills."]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Ethical Implications in HRI:"})," Research also delves into the ethical considerations of robots making decisions that affect humans, privacy concerns with robot sensing, and the psychological impact of close human-robot relationships."]}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"22-key-technologies-and-platforms",children:"2.2 Key Technologies and Platforms"}),"\n",(0,a.jsx)(n.p,{children:"The advancement of Physical AI is inextricably linked to the development and integration of sophisticated technological platforms, encompassing both software frameworks and diverse hardware systems."}),"\n",(0,a.jsx)(n.h3,{id:"221-robotics-frameworks",children:"2.2.1 Robotics Frameworks"}),"\n",(0,a.jsx)(n.p,{children:"Software frameworks provide the essential infrastructure for developing, deploying, and managing robotic applications. They offer tools for communication, hardware abstraction, and algorithm implementation:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"ROS (Robot Operating System) and ROS 2:"})," ROS is a flexible framework for writing robot software. It's not an operating system in the traditional sense, but a collection of tools, libraries, and conventions designed to simplify the task of creating complex and robust robot behaviors. ROS 2, its successor, addresses limitations of ROS 1, offering improved real-time capabilities, security, and multi-robot support, making it more suitable for production-grade applications. Both provide standardized interfaces for sensors, actuators, and communication, fostering a large and active developer community."]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"MoveIt!:"})," Built on top of ROS, MoveIt! is a state-of-the-art software library for motion planning, manipulation, and control. It provides algorithms for inverse kinematics, collision avoidance, trajectory generation, and object recognition, making it an indispensable tool for developing applications involving robot arms and mobile manipulators."]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Other Frameworks:"})," Beyond ROS, other frameworks exist, each with its strengths. Examples include Drake (a C++ toolbox for analyzing the dynamics of robots and building controllers), PyBullet (a Python module for robotics simulation, inverse kinematics, dynamics, and rendering), and various proprietary systems developed by robot manufacturers."]}),"\n"]}),"\n",(0,a.jsx)(n.h3,{id:"222-hardware-platforms-for-physical-ai",children:"2.2.2 Hardware Platforms for Physical AI"}),"\n",(0,a.jsx)(n.p,{children:"The physical manifestation of intelligence requires diverse and capable hardware. These platforms range from industrial workhorses to agile research prototypes:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Humanoid Robots:"})," These robots, designed to resemble and interact with human environments, are at the forefront of Physical AI research. Examples include Boston Dynamics' Atlas, Agility Robotics' Digit, and Unitree's H1. They push the boundaries of bipedal locomotion, balance, and dexterous manipulation, aiming for human-level versatility."]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Manipulators:"})," Robotic arms are essential for tasks requiring fine motor skills and interaction with objects. Industrial manipulators (e.g., KUKA, ABB) are robust for repetitive tasks, while collaborative robots (cobots like Universal Robots, Franka Emika) are designed to work safely alongside humans in shared workspaces. Dexterous hands and grippers are also a key research area for enhancing manipulation capabilities."]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Mobile Robots:"})," These include Autonomous Guided Vehicles (AGVs) and Autonomous Mobile Robots (AMRs) for logistics, drones for aerial inspection and delivery, and a variety of wheeled or tracked platforms for exploration and service tasks. Legged robots (quadrupeds like Boston Dynamics' Spot or Unitree's Go1) offer superior mobility in unstructured and rough terrains."]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Soft Robots:"})," Moving beyond rigid components, soft robotics explores the use of compliant materials to create robots that are inherently safer for human interaction, more adaptable to irregular shapes, and capable of novel forms of locomotion. This emerging field challenges traditional robot design paradigms."]}),"\n"]}),"\n",(0,a.jsx)(n.h3,{id:"223-computational-infrastructure",children:"2.2.3 Computational Infrastructure"}),"\n",(0,a.jsx)(n.p,{children:"The raw computational power required for Physical AI, especially with deep learning, demands sophisticated infrastructure:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"GPU Acceleration for AI Workloads:"})," Graphics Processing Units (GPUs) are fundamental for training and running deep neural networks that power perception, control, and learning algorithms in Physical AI. NVIDIA's CUDA platform and specialized AI accelerators are widely used."]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Cloud Robotics and Distributed Computation:"})," For tasks requiring immense computational resources, such as large-scale simulation, model training, or data analysis, cloud platforms provide scalable infrastructure. Cloud robotics also enables fleet management, shared learning experiences among robots, and access to centralized AI services."]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Edge AI for Low-Latency, On-Board Processing:"})," Many robotic applications demand real-time responses, which necessitate processing data directly on the robot. Edge AI involves deploying compact, efficient AI models and inference engines on embedded systems, allowing robots to make rapid decisions without relying on continuous cloud connectivity, critical for safety-critical operations."]}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"23-ethical-considerations-in-physical-ai",children:"2.3 Ethical Considerations in Physical AI"}),"\n",(0,a.jsx)(n.p,{children:"The growing capabilities and autonomy of Physical AI systems necessitate a careful examination of their ethical implications. As these robots become more integrated into society, questions of safety, responsibility, privacy, and societal impact come to the forefront."}),"\n",(0,a.jsx)(n.h3,{id:"231-safety-and-responsibility",children:"2.3.1 Safety and Responsibility"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Fail-Safe Mechanisms and Robust Design:"})," Ensuring the physical safety of humans interacting with or in proximity to robots is paramount. This requires robust engineering, redundant safety systems, and rigorous testing to prevent unintended harm or malfunction."]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Accountability in Autonomous Systems:"})," When an autonomous robot causes harm or makes a questionable decision, determining who is responsible (e.g., the manufacturer, the programmer, the operator, or the AI itself) becomes complex. Clear frameworks for accountability are needed to address liability and ensure ethical decision-making."]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Transparency and Explainability:"})," For humans to trust and work effectively with Physical AI, these systems should ideally be able to explain their actions and decisions, especially in critical situations. This is a significant challenge for complex, black-box AI models."]}),"\n"]}),"\n",(0,a.jsx)(n.h3,{id:"232-privacy-and-data-security",children:"2.3.2 Privacy and Data Security"}),"\n",(0,a.jsx)(n.p,{children:"Physical AI systems, equipped with numerous sensors, continuously collect vast amounts of data about their surroundings and the individuals within them. This raises substantial privacy and data security concerns:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Handling Sensitive Data:"})," Robots operating in homes, workplaces, or public spaces can collect personal identifying information, visual data, audio recordings, and even biometric data. Safeguarding this sensitive information from misuse or unauthorized access is critical."]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Surveillance and Data Misuse Concerns:"})," The potential for robots to be used for surveillance, either intentionally or unintentionally, poses a threat to individual liberties. Strict regulations and ethical guidelines are required to prevent such misuse."]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Data Governance and Regulatory Frameworks:"})," Clear policies are needed to govern how robotic data is collected, stored, processed, and shared. International regulations (like GDPR) provide a starting point, but specific frameworks for embodied AI are still evolving."]}),"\n"]}),"\n",(0,a.jsx)(n.h3,{id:"233-societal-impact",children:"2.3.3 Societal Impact"}),"\n",(0,a.jsx)(n.p,{children:"The widespread adoption of Physical AI will inevitably lead to profound societal changes, necessitating proactive planning and policy development:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Job Displacement and Economic Changes:"})," As robots become more capable, there are concerns about job displacement in sectors like manufacturing, logistics, and service industries. Societies need to address economic shifts, workforce retraining, and new models of labor distribution."]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Autonomous Decision-Making and Moral Agency:"}),' When robots are tasked with making life-or-death decisions (e.g., in autonomous vehicles or military applications), profound ethical dilemmas arise. The concept of "moral agency" in AI and the philosophical implications of delegating ethical choices to machines are active areas of debate.']}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Bias in AI Systems and its Physical Manifestations:"})," If AI models are trained on biased data, these biases can manifest in the physical actions of robots, potentially leading to discriminatory behavior or unfair treatment in real-world interactions. Ensuring fairness and equity in AI training data and algorithms is crucial."]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Human-Robot Relationships:"})," The psychological and social impact of humans forming relationships with highly advanced, seemingly intelligent robots is another area of emerging concern, particularly with social and companion robots."]}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"24-future-outlook",children:"2.4 Future Outlook"}),"\n",(0,a.jsx)(n.p,{children:"The field of Physical AI is on the cusp of transformative advancements, with both near-term breakthroughs and long-term visions promising to reshape our world."}),"\n",(0,a.jsx)(n.h3,{id:"241-near-term-breakthroughs",children:"2.4.1 Near-Term Breakthroughs"}),"\n",(0,a.jsx)(n.p,{children:"In the coming years, we can anticipate several significant developments:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"More Robust Sim2Real Transfer:"})," Improved techniques will make it easier and more reliable to transfer skills learned in simulation to physical robots, accelerating the deployment of new robotic capabilities across industries."]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Widespread Adoption of Collaborative Robots:"})," Cobots will become even more common in manufacturing, logistics, and service sectors, safely working alongside humans and augmenting their capabilities in tasks ranging from assembly to healthcare."]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Improved Human-Robot Collaboration in Daily Tasks:"})," Robots will develop more nuanced understandings of human intentions and social cues, leading to smoother and more intuitive collaboration in everyday environments, from household assistance to educational settings."]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Enhanced Dexterous Manipulation:"})," Advancements in tactile sensing, gripping mechanisms, and AI control will enable robots to perform increasingly complex and delicate manipulation tasks, handling novel objects with human-like precision."]}),"\n"]}),"\n",(0,a.jsx)(n.h3,{id:"242-long-term-vision",children:"2.4.2 Long-Term Vision"}),"\n",(0,a.jsx)(n.p,{children:"Looking further ahead, the long-term vision for Physical AI is nothing short of revolutionary:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"General-Purpose Humanoid Robots:"})," The development of highly versatile humanoid robots capable of performing a wide array of tasks in unstructured human environments, moving beyond specialized applications. These robots could serve as personal assistants, caregivers, or even general laborers."]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"AI Systems That Can Continuously Learn and Adapt Over Decades:"})," Imagine robots that evolve their intelligence and skills over their entire operational lifetime, constantly learning from new experiences and adapting to changing environments and tasks without human intervention."]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Fully Autonomous Exploration and Construction:"})," Robots capable of exploring unknown territories (e.g., space, deep sea, disaster zones) and undertaking complex construction projects entirely autonomously, from resource gathering to final assembly."]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Self-Replicating Robotics:"})," A more speculative long-term vision involves robots capable of self-replication, using available materials to build new robots, potentially accelerating exploration and colonization efforts in extreme environments."]}),"\n"]}),"\n",(0,a.jsx)(n.h3,{id:"243-challenges-ahead",children:"2.4.3 Challenges Ahead"}),"\n",(0,a.jsx)(n.p,{children:"Despite the exciting prospects, significant challenges remain that require continued research and innovation:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Scaling Embodied Intelligence to Human-Level Complexity:"})," Reaching the cognitive and motor dexterity of humans in a robotic system remains a grand challenge, demanding breakthroughs in various subfields of AI and robotics."]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Energy Efficiency and Material Science Advancements:"})," Many advanced robotic systems are energy-intensive. Innovations in battery technology, energy harvesting, and more efficient actuators are crucial for extending operational durations and reducing environmental impact. Advances in materials science, especially for soft robotics, are also critical for developing safer and more adaptable robots."]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Bridging the Gap Between Perception, Cognition, and Action:"})," Seamlessly integrating robust perception (understanding the world), high-level cognition (reasoning and planning), and agile physical action (manipulation and locomotion) is essential for truly intelligent embodied behavior."]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Ethical Governance and Public Acceptance:"})," As Physical AI progresses, proactively establishing ethical guidelines, regulatory frameworks, and fostering public understanding and acceptance will be crucial for responsible development and integration into society."]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Robustness to Adversarial Attacks:"})," Ensuring that Physical AI systems are resilient to malicious attacks or unintended perturbations that could compromise their safety or functionality."]}),"\n"]}),"\n",(0,a.jsx)(n.p,{children:"The future of Physical AI holds immense promise, offering solutions to some of humanity's most pressing challenges and opening new frontiers for exploration and innovation. The journey will be complex, but the potential rewards are boundless."})]})}function h(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(d,{...e})}):d(e)}},8453:(e,n,i)=>{i.d(n,{R:()=>t,x:()=>r});var o=i(6540);const a={},s=o.createContext(a);function t(e){const n=o.useContext(s);return o.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function r(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:t(e.components),o.createElement(s.Provider,{value:n},e.children)}}}]);